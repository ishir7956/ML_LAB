{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "884999e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv(\"lab11.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127143da",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b27dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook:\n",
      "  sunny:\n",
      "    humidity:\n",
      "      high:\n",
      "          Class: no\n",
      "      medium:\n",
      "          Class: yes\n",
      "  overcast:\n",
      "      Class: yes\n",
      "  rain:\n",
      "    wind:\n",
      "      weak:\n",
      "          Class: yes\n",
      "      strong:\n",
      "          Class: no\n",
      "The predicted class for the new sample is: yes\n"
     ]
    }
   ],
   "source": [
    "def entropy(data):\n",
    "    labels = data['decision']\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / len(labels)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def information_gain(data, attribute):\n",
    "    total_entropy = entropy(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_entropy = 0\n",
    "\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        weighted_entropy += (len(subset) / len(data)) * entropy(subset)\n",
    "\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain\n",
    "\n",
    "def id3(data, features, target_attribute):\n",
    "    if len(data['decision'].unique()) == 1:\n",
    "        return data['decision'].iloc[0]\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        return data['decision'].value_counts().idxmax()\n",
    "    \n",
    "    information_gains = {f: information_gain(data, f) for f in features}\n",
    "    best_feature = max(information_gains, key=information_gains.get)\n",
    "    \n",
    "    tree = {best_feature: {}}\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "    \n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        tree[best_feature][value] = id3(subset, remaining_features, target_attribute)\n",
    "    \n",
    "    return tree\n",
    "def print_tree(tree, depth=0):\n",
    "    if type(tree) == dict:\n",
    "        for key, value in tree.items():\n",
    "            print(\"  \" * depth + f\"{key}:\")\n",
    "            print_tree(value, depth + 1)\n",
    "    else:\n",
    "        print(\"  \" * (depth + 1) + f\"Class: {tree}\")\n",
    "def classify_id3(tree, sample):\n",
    "    if isinstance(tree, str):\n",
    "        return tree\n",
    "    else:\n",
    "        attribute = list(tree.keys())[0]\n",
    "        attribute_value = sample[attribute]\n",
    "        if attribute_value in tree[attribute]:\n",
    "            return classify_id3(tree[attribute][attribute_value], sample)\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "new_sample = {\n",
    "    'outlook': 'sunny',\n",
    "    'temp': 'medium',\n",
    "    'humidity': 'medium',\n",
    "    'wind': 'strong'\n",
    "}\n",
    "features = ['outlook', 'temp', 'humidity', 'wind']\n",
    "target_attribute = 'decision'\n",
    "\n",
    "decision_tree = id3(df, features, target_attribute)\n",
    "print_tree(decision_tree)\n",
    "result = classify_id3(decision_tree, new_sample)\n",
    "print(f\"The predicted class for the new sample is: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53077d",
   "metadata": {},
   "source": [
    "# C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8228fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook:\n",
      "  sunny:\n",
      "    humidity:\n",
      "      high:\n",
      "          Class: no\n",
      "      medium:\n",
      "          Class: yes\n",
      "  overcast:\n",
      "      Class: yes\n",
      "  rain:\n",
      "    wind:\n",
      "      weak:\n",
      "          Class: yes\n",
      "      strong:\n",
      "          Class: no\n",
      "The predicted class for the new sample is: yes\n"
     ]
    }
   ],
   "source": [
    "def entropy(data):\n",
    "    labels = data['decision']\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / len(labels)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def gain_ratio(data, attribute):\n",
    "    total_entropy = entropy(data)\n",
    "    attribute_values = data[attribute].unique()\n",
    "    weighted_entropy = 0\n",
    "    intrinsic_info = 0\n",
    "\n",
    "    for value in attribute_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        weight = len(subset) / len(data)\n",
    "        weighted_entropy += weight * entropy(subset)\n",
    "        intrinsic_info += -weight * math.log2(weight)\n",
    "\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    gain_ratio = gain / intrinsic_info if intrinsic_info != 0 else 0\n",
    "    return gain_ratio\n",
    "\n",
    "def c45(data, features, target_attribute):\n",
    "    if len(data['decision'].unique()) == 1:\n",
    "        return data['decision'].iloc[0]\n",
    "\n",
    "    if len(features) == 0:\n",
    "        return data['decision'].value_counts().idxmax()\n",
    "\n",
    "    gain_ratios = {f: gain_ratio(data, f) for f in features}\n",
    "    best_feature = max(gain_ratios, key=gain_ratios.get)\n",
    "\n",
    "    tree = {best_feature: {}}\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        tree[best_feature][value] = c45(subset, remaining_features, target_attribute)\n",
    "\n",
    "    return tree\n",
    "def print_tree(tree, depth=0):\n",
    "    if type(tree) == dict:\n",
    "        for key, value in tree.items():\n",
    "            print(\"  \" * depth + f\"{key}:\")\n",
    "            print_tree(value, depth + 1)\n",
    "    else:\n",
    "        print(\"  \" * (depth + 1) + f\"Class: {tree}\")\n",
    "def classify_c45(tree, sample):\n",
    "    if isinstance(tree, dict):\n",
    "        attribute = list(tree.keys())[0]\n",
    "        attribute_value = sample[attribute]\n",
    "        if attribute_value in tree[attribute]:\n",
    "            return classify_c45(tree[attribute][attribute_value], sample)\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    else:\n",
    "        return tree\n",
    "features = ['outlook', 'temp', 'humidity', 'wind']\n",
    "target_attribute = 'decision'\n",
    "decision_tree = c45(df, features, target_attribute)\n",
    "print_tree(decision_tree)\n",
    "new_sample = {\n",
    "    'outlook': 'sunny',\n",
    "    'temp': 'medium',\n",
    "    'humidity': 'medium',\n",
    "    'wind': 'strong'\n",
    "}\n",
    "result = classify_c45(decision_tree, new_sample)\n",
    "print(f\"The predicted class for the new sample is: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6535d",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa599b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision is 'no'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    'day': list(range(1, 15)),\n",
    "    'outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain'],\n",
    "    'temp': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'humidity': ['high', 'high', 'medium', 'high', 'high', 'medium', 'low', 'high', 'medium', 'high', 'medium', 'high', 'medium', 'high'],\n",
    "    'wind': ['weak', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'strong'],\n",
    "    'decision': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a class for a Decision Tree Node\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "# Define the CART algorithm for building a decision tree\n",
    "def cart(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    num_parent = [np.sum(y == 0), np.sum(y == 1)]  # Convert 'no' to 0 and 'yes' to 1\n",
    "    gini = 1.0 - sum((n / n_samples) ** 2 for n in num_parent)\n",
    "\n",
    "    best_gini = 0\n",
    "    best_idx, best_thr = None, None\n",
    "\n",
    "    for idx in range(n_features):\n",
    "        thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "        num_left = [0, 0]\n",
    "        num_right = num_parent.copy()\n",
    "\n",
    "        for i in range(1, n_samples):\n",
    "            c = classes[i - 1]\n",
    "            num_left[c] += 1\n",
    "            num_right[c] -= 1\n",
    "            gini_left = 1.0 - sum(\n",
    "                (num_left[x] / i) ** 2 for x in range(2)\n",
    "            )\n",
    "            gini_right = 1.0 - sum(\n",
    "                (num_right[x] / (n_samples - i)) ** 2 for x in range(2)\n",
    "            )\n",
    "            gini = (i * gini_left + (n_samples - i) * gini_right) / n_samples\n",
    "            if thresholds[i] == thresholds[i - 1]:\n",
    "                continue\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_idx = idx\n",
    "                best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "    if best_gini == 0:\n",
    "        return DecisionTreeNode(\n",
    "            gini=best_gini,\n",
    "            num_samples=n_samples,\n",
    "            num_samples_per_class=num_parent,\n",
    "            predicted_class=np.argmax(num_parent),\n",
    "        )\n",
    "    X_left, y_left, X_right, y_right = X[X[:, best_idx] <= best_thr], y[X[:, best_idx] <= best_thr], X[X[:, best_idx] > best_thr], y[X[:, best_idx] > best_thr]\n",
    "    left = cart(X_left, y_left)\n",
    "    right = cart(X_right, y_right)\n",
    "    return DecisionTreeNode(\n",
    "        gini=best_gini,\n",
    "        num_samples=n_samples,\n",
    "        num_samples_per_class=num_parent,\n",
    "        predicted_class=np.argmax(num_parent),\n",
    "        feature_index=best_idx,\n",
    "        threshold=best_thr,\n",
    "        left=left,\n",
    "        right=right,\n",
    "    )\n",
    "\n",
    "# Prepare the data\n",
    "X = df[['outlook', 'temp', 'humidity', 'wind']]\n",
    "y = df['decision']\n",
    "X = pd.get_dummies(X)  # One-hot encode categorical features\n",
    "\n",
    "# Build the decision tree\n",
    "X = X.to_numpy()\n",
    "y = (y == 'yes').astype(int)  # Convert 'yes' to 1 and 'no' to 0\n",
    "tree = cart(X, y)\n",
    "\n",
    "# Define a function to make predictions using the tree\n",
    "def predict_tree(node, x):\n",
    "    if node.feature_index is None:\n",
    "        return node.predicted_class\n",
    "    if x[node.feature_index] <= node.threshold:\n",
    "        if node.left is not None:\n",
    "            return predict_tree(node.left, x)\n",
    "    else:\n",
    "        if node.right is not None:\n",
    "            return predict_tree(node.right, x)\n",
    "\n",
    "# Test the decision tree with a sample input\n",
    "sample_input = np.array([0, 0, 0, 1])  # Sample input: ['outlook_overcast', 'temp_high', 'humidity_high', 'wind_strong']\n",
    "prediction = predict_tree(tree, sample_input)\n",
    "\n",
    "if prediction == 1:\n",
    "    print(\"The decision is 'yes'\")\n",
    "else:\n",
    "    print(\"The decision is 'no'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4174e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
